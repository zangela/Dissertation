}
k = length(coln)+1
if(length(tmp > 0))
{
for (i in 1:length(tmp))
{
dic[k]=tmp[i]
k = k+1
}
}
return(dic)
}
n_part = 50
part = as.integer(nrow(datidef)/n_part)
tmp = rep("", 0)
for (i in 1:(n_part+1))
{
if (i <= 50)
{
if (i == 1)
{
corpus = Corpus(VectorSource(datidef[1:part*i,12]))
tmp = make_dictionary(corpus,tmp)
print(tmp)
}
else
{
corpus = Corpus(VectorSource(datidef[(part*(i-1)+1):(part*i),12]))
tmp = make_dictionary(corpus,tmp)
#print(tmp)
}
}
else
{
if (part*(i-1) < nrow(datidef))
{
corpus = Corpus(VectorSource(datidef[(part*(i-1)+1):nrow(datidef),12]))
dic = make_dictionary(corpus,tmp)
print(dic)
}
}
}
dic= wordStem(dic, language = "english")
dic= wordStem(dic, language = "italian")
dic= wordStem(dic, language = "spanish")
dic= wordStem(dic, language = "danish")
dic= wordStem(dic, language = "french")
dic= wordStem(dic, language = "german")
len = 0
idx = 1
dic=sort(dic)
colnfin = dic
#conto il numero di parole diverse in tutti gli oggetti
for (i in 2:length(dic))
{
if (colnfin[idx]!=dic[i])
{
len = len +1
idx = idx + 1
colnfin[idx]=dic[i]
}
}
#creo un vettore per memorizzare tutte le parole diverse (serve per colnames) e la matrice objdef finale
dictionary=character(len)
#inserisco tutte le parole diverse in oarine alfabetico in word
for (i in 1:len)
{
dictionary[i]= colnfin[i]
}
##################################################################
#
#
#
#   fine CREAZIONE DEL DIZIONARIO NEL CASO ALLDEF.CSV
#   presente in ***dictionary***
#
#
##################################################################
make_dictionary <- function(corpus, tmp)
{
dtm = as.matrix(DocumentTermMatrix(corpus
, control = list( stemming = TRUE, stopwords = itastopwords,
minWordLength = 2, removeNumbers = TRUE,
removePunctuation = FALSE, bounds=list(local = c(1,Inf)) ))
)
coln = colnames(dtm)
dic = rep("", length(coln)+length(tmp))
for (i in 1:length(coln))
{
dic[i]=coln[i]
}
k = length(coln)+1
if(length(tmp > 0))
{
for (i in 1:length(tmp))
{
dic[k]=tmp[i]
k = k+1
}
}
return(dic)
}
n_part = 50
part = as.integer(nrow(datidef)/n_part)
tmp = rep("", 0)
for (i in 1:(n_part+1))
{
if (i <= 50)
{
if (i == 1)
{
corpus = Corpus(VectorSource(datidef[1:part*i,12]))
tmp = make_dictionary(corpus,tmp)
print(tmp)
}
else
{
corpus = Corpus(VectorSource(datidef[(part*(i-1)+1):(part*i),12]))
tmp = make_dictionary(corpus,tmp)
#print(tmp)
}
}
else
{
if (part*(i-1) < nrow(datidef))
{
corpus = Corpus(VectorSource(datidef[(part*(i-1)+1):nrow(datidef),12]))
dic = make_dictionary(corpus,tmp)
print(dic)
}
}
}
library(SnowballC)
#(= una riga per oggetto, una colonna per ogni parola)
corpus = Corpus(VectorSource(datidef[,12]))
library(SnowballC)
library(ggplot2)
library(tm)
library(lsa)
library(caret)
library(wordcloud)
library(devtools) #installarla se necessario
library (TextWiller)
library(ggplot2)
require(tau)
#(= una riga per oggetto, una colonna per ogni parola)
corpus = Corpus(VectorSource(datidef[,12]))
##################################################################
#
#
#
#   inizio CREAZIONE DEL DIZIONARIO NEL CASO ALLDEF.CSV
#
#
#
##################################################################
make_dictionary <- function(corpus, tmp)
{
dtm = as.matrix(DocumentTermMatrix(corpus
, control = list( stemming = TRUE, stopwords = itastopwords,
minWordLength = 2, removeNumbers = TRUE,
removePunctuation = FALSE, bounds=list(local = c(1,Inf)) ))
)
coln = colnames(dtm)
dic = rep("", length(coln)+length(tmp))
for (i in 1:length(coln))
{
dic[i]=coln[i]
}
k = length(coln)+1
if(length(tmp > 0))
{
for (i in 1:length(tmp))
{
dic[k]=tmp[i]
k = k+1
}
}
return(dic)
}
n_part = 50
part = as.integer(nrow(datidef)/n_part)
tmp = rep("", 0)
for (i in 1:(n_part+1))
{
if (i <= 50)
{
if (i == 1)
{
corpus = Corpus(VectorSource(datidef[1:part*i,12]))
tmp = make_dictionary(corpus,tmp)
print(tmp)
}
else
{
corpus = Corpus(VectorSource(datidef[(part*(i-1)+1):(part*i),12]))
tmp = make_dictionary(corpus,tmp)
#print(tmp)
}
}
else
{
if (part*(i-1) < nrow(datidef))
{
corpus = Corpus(VectorSource(datidef[(part*(i-1)+1):nrow(datidef),12]))
dic = make_dictionary(corpus,tmp)
print(dic)
}
}
}
dic= wordStem(dic, language = "english")
dic= wordStem(dic, language = "italian")
dic= wordStem(dic, language = "spanish")
dic= wordStem(dic, language = "danish")
dic= wordStem(dic, language = "french")
dic= wordStem(dic, language = "german")
len = 0
idx = 1
dic=sort(dic)
colnfin = dic
#conto il numero di parole diverse in tutti gli oggetti
for (i in 2:length(dic))
{
if (colnfin[idx]!=dic[i])
{
len = len +1
idx = idx + 1
colnfin[idx]=dic[i]
}
}
#creo un vettore per memorizzare tutte le parole diverse (serve per colnames) e la matrice objdef finale
dictionary=character(len)
#inserisco tutte le parole diverse in oarine alfabetico in word
for (i in 1:len)
{
dictionary[i]= colnfin[i]
}
##################################################################
#
#
#
#   fine CREAZIONE DEL DIZIONARIO NEL CASO ALLDEF.CSV
#   presente in ***dictionary***
#
#
##################################################################
len
#
#
#
#creo la matrice finale dei domini dei sender che conta la presenza dei singoli domini
#
#
#
#
##################################################################
#ottengo tutti i dominii
len = 0
alldom=datidef[,8]
#dominii in ordine alfabetico
alldom= sort(alldom)
#conto e mi salvo tutti i dominii diversi
tmpdom = character(nrow(datidef))
idx=1
tmpdom[idx]=toString(alldom[idx])
len=1
for (i in 2:nrow(datidef))
{
if (tmpdom[idx]!=toString(alldom[i]))
{
len = len +1
idx=idx+1
tmpdom[idx]=toString(alldom[i])
}
}
#creo un vettore che contiene tutti i dominii Diversi (serve per colnames) e la matrice sendomdef finale
senderdom= character(len)
for (i in 1:len)
{
senderdom[i]=tmpdom[i]
}
sendomdef = matrix(0, nrow=nrow(datidef), ncol=len)
#creo la matrice finale
for (i in 1:nrow(sendomdef))
{
for (j in 1:length(senderdom))
{
if (datidef[i,8]== senderdom[j])
{
sendomdef[i,j]= 1
j = length(senderdom)+1
}
}
}
senderdom
length(domain)
len = 0
alldom=datidef[,8]
#dominii in ordine alfabetico
alldom= sort(alldom)
#conto e mi salvo tutti i dominii diversi
tmpdom = character(nrow(datidef))
idx=1
tmpdom[idx]=toString(alldom[idx])
len=1
for (i in 2:nrow(datidef))
{
if (tmpdom[idx]!=toString(alldom[i]))
{
len = len +1
idx=idx+1
tmpdom[idx]=toString(alldom[i])
}
}
#creo un vettore che contiene tutti i dominii Diversi (serve per colnames) e la matrice sendomdef finale
domain= character(len)
for (i in 1:len)
{
domain[i]=tmpdom[i]
}
length(domain)
memory.limit()
memory.limit(150000)
memory.limit(150000)
memory.limit()
corpus = Corpus(VectorSource(datidef[,12]))
#
# #se facciamo stemming
#
# #NB: servirebbero 140 g di memoria per lanciare questo comando->dunque così completo non è possibile lanciarlo. Capire come gestirlo.
dtm = as.matrix(DocumentTermMatrix(corpus
, control = list( stemming = TRUE, stopwords = itastopwords,
minWordLength = 2, removeNumbers = TRUE,
removePunctuation = FALSE, bounds=list(local = c(1,Inf)) ))
)
memory.limit(170000)
corpus = Corpus(VectorSource(datidef[,12]))
#
# #se facciamo stemming
#
# #NB: servirebbero 140 g di memoria per lanciare questo comando->dunque così completo non è possibile lanciarlo. Capire come gestirlo.
dtm = as.matrix(DocumentTermMatrix(corpus
, control = list( stemming = TRUE, stopwords = itastopwords,
minWordLength = 2, removeNumbers = TRUE,
removePunctuation = FALSE, bounds=list(local = c(1,Inf)) ))
)
memory.limit()
#correttamente tutte le email mandate dal dominio interno passano per il Firewall senza essere bloccate->risultato scontao
barplot(esterne, ylab="Frequenze relative", main="Distr per mittenti esterni",ylim=(0:1), col=2:4)
freqass_sb      #->sarebbe l'errore commesso da parte del Firewall
conteggio
freqrel_fascia
barplot(f/sum(freq_mese), ylab="Frequenze relative", main="Distribuzione email per Mese", col=2:5, ylim=c(0:1))
par(mfrow=c(2,2))
barplot(agosto, ylab="Frequenze relative", main="Distr Agosto",ylim=(0:1), col=2:4)
barplot(settembre, ylab="Frequenze relative", main="Distr Settembre",ylim=(0:1), col=2:4)
barplot(ottobre, ylab="Frequenze relative", main="Distr Ottobre",ylim=(0:1), col=2:4)
barplot(novembre, ylab="Frequenze relative", main="Distr Novembre",ylim=(0:1), col=2:4)
par(mfrow=c(1,1))
barplot(cbind(int_rel,ext_rel), ylab="Frequenze relative", main="Distr nelle email passate",ylim=(0:1), col=2:3)
boxplot(nchars~datidef[,5],col=2:4)
boxplot(nchars~datidef[,5],col=2:4, main="Distribuzione dei caratteri per tipologia di Y", ylab="Freq assolute")
length(grep("EMOTE",datidef[,12])) #il numero di emoticons trovate in tot
dat=data.frame(objdef, datidef[,6])
svm_data <- function(type, vector, min, max)
{
# la variabile type contiene il fatto che si debba calcolare objdef, domdef o altro
# la variabile vector contiene il dizionario di parole o di dominii in base al type
# min % max è il range di indice di datidef che vengono analizzati
# in una singola esecuzione per il calcolo degli input/output di svm
# SEMPLICE: creo objdef e domdef per le righe di datidef che vanno da min a max ;)
if (type == 0) # calcolo di objdef
{
col= 49
mat = matrix(0, nrow=(max-min), ncol=length(dictionary))
for (i in 1:(max-min))
{
#print(datidef[i,12])
obj = strsplit(toString(datidef[i, 12]), " ")
#print(obj)
for (j in 1:length(obj[[1]]))
{
obj[[1]][j] = wordStem(obj[[1]][j], language = "english")
obj[[1]][j] = wordStem(obj[[1]][j], language = "italian")
obj[[1]][j] = wordStem(obj[[1]][j], language = "spanish")
obj[[1]][j] = wordStem(obj[[1]][j], language = "danish")
obj[[1]][j] = wordStem(obj[[1]][j], language = "french")
obj[[1]][j] = wordStem(obj[[1]][j], language = "german")
}
#print(obj[[1]])
for (k in 1:length(obj[[1]]))
{
if (obj[[1]][k]!= "")
{
position=pmatch(obj[[1]][k], dictionary)
print(position[[1]])
print("ok")
if (is.na(position[[1]])==FALSE)
{
print(length(dictionary))
print(ncol(mat))
mat[i,position[[1]]]=1
}
}
}
}
#for to compute
}
else if (type == 1) # calcolo di domdef
{
col= 49
#mat = matrix(0, nrow=(max-min), ncol=col)
#for to compute
}
else if (type == 2) # calcolo motivation
{
col= 49
#mat = matrix(0, nrow=(max-min), ncol=col)
#for to compute
}
return(mat)
}
k = svm_data(0, dictionary, 1,2)
# Chiamiamo i pacchetti necessari
library(MASS)
library(tidyverse)
#carico le librerie necessarie
library(tm)
library(lsa)
library(caret)
library(wordcloud)
library(devtools) #installarla se necessario
library (TextWiller)
library(ggplot2)
require(tau)
library(e1071)
library(ggplot2)
library(SnowballC)
k = svm_data(0, dictionary, 1,2)
for (i in 1:ncol(k))
{
if (k[1,i]==1)
{
print("HELLO BITCH")
}
}
svm_data <- function(type, vector, min, max)
{
# la variabile type contiene il fatto che si debba calcolare objdef, domdef o altro
# la variabile vector contiene il dizionario di parole o di dominii in base al type
# min % max è il range di indice di datidef che vengono analizzati
# in una singola esecuzione per il calcolo degli input/output di svm
# SEMPLICE: creo objdef e domdef per le righe di datidef che vanno da min a max ;)
if (type == 0) # calcolo di objdef
{
col= 49
mat = matrix(0, nrow=(max-min), ncol=length(dictionary))
for (i in 1:(max-min))
{
#print(datidef[i,12])
obj = strsplit(toString(datidef[i, 12]), " ")
#print(obj)
for (j in 1:length(obj[[1]]))
{
obj[[1]][j] = wordStem(obj[[1]][j], language = "english")
obj[[1]][j] = wordStem(obj[[1]][j], language = "italian")
obj[[1]][j] = wordStem(obj[[1]][j], language = "spanish")
obj[[1]][j] = wordStem(obj[[1]][j], language = "danish")
obj[[1]][j] = wordStem(obj[[1]][j], language = "french")
obj[[1]][j] = wordStem(obj[[1]][j], language = "german")
}
#print(obj[[1]])
for (k in 1:length(obj[[1]]))
{
if (obj[[1]][k]!= "")
{
position=pmatch(obj[[1]][k], dictionary)
print(position[[1]])
print("ok")
if (is.na(position[[1]])==FALSE)
{
print(length(dictionary))
print(ncol(mat))
mat[i,position[[1]]]=1
}
}
}
}
#for to compute
}
else if (type == 1) # calcolo di domdef
{
col= 49
#mat = matrix(0, nrow=(max-min), ncol=col)
#for to compute
}
else if (type == 2) # calcolo motivation
{
col= 49
#mat = matrix(0, nrow=(max-min), ncol=col)
#for to compute
}
return(mat)
}
k = svm_data(0, dictionary, 1,2)
for (i in 1:ncol(k))
{
if (k[1,i]==1)
{
print("HELLO BITCH")
}
}
